{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as Layers\nimport tensorflow.keras.activations as Actications\nimport tensorflow.keras.models as Models\nimport tensorflow.keras.optimizers as Optimizer\nimport tensorflow.keras.metrics as Metrics\nimport tensorflow.keras.utils as Utils\nfrom keras.utils.vis_utils import model_to_dot\nimport os\nimport matplotlib.pyplot as plot\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom random import randint\nfrom IPython.display import SVG\nimport matplotlib.gridspec as gridspec\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_images(directory):\n    Images = []\n    Labels = []  # 0 for Building , 1 for forest, 2 for glacier, 3 for mountain, 4 for Sea , 5 for Street\n    label = 0\n    \n    for labels in os.listdir(directory): #Main Directory where each class label is present as folder name.\n        if labels == 'glacier': #Folder contain Glacier Images get the '2' class label.\n            label = 2\n        elif labels == 'sea':\n            label = 4\n        elif labels == 'buildings':\n            label = 0\n        elif labels == 'forest':\n            label = 1\n        elif labels == 'street':\n            label = 5\n        elif labels == 'mountain':\n            label = 3\n        \n        for image_file in os.listdir(directory+labels): #Extracting the file name of the image from Class Label folder\n            image = cv2.imread(directory+labels+r'/'+image_file) #Reading the image (OpenCV)\n            image = cv2.resize(image,(150,150)) #Resize the image, Some images are different sizes. (Resizing is very Important)\n            Images.append(image)\n            Labels.append(label)\n    \n    return shuffle(Images,Labels,random_state=817328462) #Shuffle the dataset you just prepared.\n\ndef get_classlabel(class_code):\n    labels = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}\n    \n    return labels[class_code]","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Images, Labels = get_images('../input/seg_train/seg_train/') #Extract the training images from the folders.\n\nImages = np.array(Images) #converting the list of images to numpy array.\nLabels = np.array(Labels)","metadata":{"_uuid":"02d98dc337916af5e96d7441b966de394a6ce2f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets find shape of our traing data.\n\nAs you see, The Training data is in shape of (Number of Training Images, Width of image, Height of image, Channel of image). This shape is very important. If you didnot resize the images to same size. It should be (No. of images,) shape. So, using this shape you cant feed the images to the model.","metadata":{"_uuid":"905a9db8c8dbb9d0d484db1dc7fc0e4047616633"}},{"cell_type":"code","source":"print(\"Shape of Images:\",Images.shape)\nprint(\"Shape of Labels:\",Labels.shape)","metadata":{"_uuid":"2576fdbadc9754b2f9a7ced3d746ab6ecf5e06aa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us look some random images of our dataset.","metadata":{"_uuid":"34c0f25ba008f208ffc1d7ae35720b43a1c14239"}},{"cell_type":"code","source":"f,ax = plot.subplots(5,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(0,5,1):\n    for j in range(0,5,1):\n        rnd_number = randint(0,len(Images))\n        ax[i,j].imshow(Images[rnd_number])\n        ax[i,j].set_title(get_classlabel(Labels[rnd_number]))\n        ax[i,j].axis('off')","metadata":{"_uuid":"479729a0005f37957e4428897a8b8aa862c6c247","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, Create the CNN model to predict the class labels.This is the basic CNN model.","metadata":{"_uuid":"b8b8ea230c599cb29e23712e84a6097f0a62ed22"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as Layers\nfrom tensorflow.keras.utils import plot_model\nimport tensorflow.keras.activations as Actications\nfrom tensorflow.keras.optimizers import SGD\nimport tensorflow.keras.models as Models\nimport tensorflow.keras.optimizers as Optimizer\nimport tensorflow.keras.metrics as Metrics\nimport tensorflow.keras.utils as Utils\nfrom keras.utils.vis_utils import model_to_dot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Models.Sequential()\n\nmodel.add(Layers.Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.MaxPool2D(5,5))\nmodel.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(140,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(100,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(50,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.MaxPool2D(5,5))\nmodel.add(Layers.Flatten())\nmodel.add(Layers.Dense(180,activation='relu'))\nmodel.add(Layers.Dense(100,activation='relu'))\nmodel.add(Layers.Dropout(rate=0.5))\nmodel.add(Layers.Dense(50,activation='relu'))\nmodel.add(Layers.Dropout(rate=0.5))\nmodel.add(Layers.Dense(6,activation='softmax'))\n\nmodel.compile(optimizer=Optimizer.Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nUtils.plot_model(model,to_file='model.png',show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained = model.fit(Images,Labels,epochs=40,validation_split=0.30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images,test_labels = get_images('../input/seg_test/seg_test/')\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)\ny_pred1=model.predict_classes(test_images)\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Models.Sequential()\n\nmodel.add(Layers.Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.MaxPool2D(5,5))\nmodel.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(140,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(100,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(50,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.MaxPool2D(5,5))\nmodel.add(Layers.Flatten())\nmodel.add(Layers.Dense(180,activation='relu'))\nmodel.add(Layers.Dense(100,activation='relu'))\nmodel.add(Layers.Dense(50,activation='relu'))\nmodel.add(Layers.Dropout(rate=0.5))\nmodel.add(Layers.Dense(6,activation='softmax'))\n\nmodel.compile(optimizer=Optimizer.Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nUtils.plot_model(model,to_file='model.png',show_shapes=True)","metadata":{"_uuid":"9612c73f84ac75ac1af4f07bd6cf8306ceb21558","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained = model.fit(Images,Labels,epochs=35,validation_split=0.30)","metadata":{"_uuid":"a75627185debd77e0ff911bdb5743f1f6a17d960","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.plot(trained.history['acc'])\nplot.plot(trained.history['val_acc'])\nplot.title('Model accuracy')\nplot.ylabel('Accuracy')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()\n\nplot.plot(trained.history['loss'])\nplot.plot(trained.history['val_loss'])\nplot.title('Model loss')\nplot.ylabel('Loss')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()","metadata":{"_uuid":"4b61a715110508d46b356a811df296e08d3b5b4a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images,test_labels = get_images('../input/seg_test/seg_test/')\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)\ny_pred1=model.predict_classes(test_images)\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","metadata":{"_uuid":"82666c897661762e3908ee4d4095610b668ef62f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nconfusion_matrix(test_labels, y_pred1)\n\n\nprecision_scoreM1=precision_score(test_labels, y_pred1, average=None)\nprint(\"\\n Model-1 Precision_score\\n\", precision_scoreM1)\n\nrecall_scoreM1=recall_score(test_labels, y_pred1, average=None)\nprint(\"\\n Model-1 Recall_score\\n\",recall_scoreM1)\n\naccuracy_scoreM1=accuracy_score(test_labels, y_pred1)\nprint(\"\\n Model-1 Accuracy_score\\n\",accuracy_scoreM1)\n\nf1_scoreM1=f1_score(test_labels, y_pred1, average=None)\nprint(\"\\n Model-1 F1_score\\n\",f1_scoreM1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model 2**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=Optimizer.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\ntrained = model.fit(Images,Labels,epochs=35,validation_split=0.20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.plot(trained.history['acc'])\nplot.plot(trained.history['val_acc'])\nplot.title('Model accuracy')\nplot.ylabel('Accuracy')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()\n\nplot.plot(trained.history['loss'])\nplot.plot(trained.history['val_loss'])\nplot.title('Model loss')\nplot.ylabel('Loss')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images,test_labels = get_images('../input/seg_test/seg_test/')\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)\ny_pred1=model.predict_classes(test_images)\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}